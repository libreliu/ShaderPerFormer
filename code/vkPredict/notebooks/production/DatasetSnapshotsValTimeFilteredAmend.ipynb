{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset snapshot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train / Test / val Presplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shaders that took part in the partition: 20669\n",
      "['3d23DR' '3d23Dc' '3d23R3' ... 'wtyfzz' 'wtyyWD' 'wtyyz3']\n",
      "['wd3GDH' '3sXyDn' 'MdK3Dd' ... 'WltBzM' 'MsVXzc' 'sdVGWW']\n",
      "numTrain: 16535; numTest: 1033; numVal: 3101\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.path.join(os.path.abspath(''), '../../'))\n",
    "sys.path.append(os.path.join(os.path.abspath(''), '../../toyDb'))\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "from toyDb.databases import ExperimentDb\n",
    "ExperimentDb.init_from_default_db()\n",
    "\n",
    "def getShaderIdSplit() -> 'np.array':\n",
    "  # Good, let's hard code the submission ddl for I3D'24\n",
    "  RNGSeed = 20240105\n",
    "  TRAIN_RATIO = 0.8\n",
    "  TEST_RATIO = 0.05\n",
    "\n",
    "  CACHE = os.path.join(os.path.abspath(''), 'shaderIdSplitCache.json')\n",
    "\n",
    "  # this is complete (than ImageOnlyShader)\n",
    "  allShaderIdQuery = ExperimentDb.ImageOnlyExperiment.select(\n",
    "    ExperimentDb.ImageOnlyExperiment.shader_shadertoy_id\n",
    "  ).order_by(ExperimentDb.ImageOnlyExperiment.shader_shadertoy_id.asc()).distinct()\n",
    "\n",
    "  # the db in use have 20669 is_imageonly shaders\n",
    "  print(f\"Shaders that took part in the partition: {len(allShaderIdQuery)}\")\n",
    "  assert(len(allShaderIdQuery) == 20669)\n",
    "\n",
    "  rng = np.random.default_rng(RNGSeed)\n",
    "\n",
    "  shaderIds = np.array([i.shader_shadertoy_id for i in allShaderIdQuery])\n",
    "  shuffledIds = rng.permutation(shaderIds)\n",
    "  print(shaderIds)\n",
    "  print(shuffledIds)\n",
    "\n",
    "  if not os.path.isfile(CACHE):  \n",
    "    with open(CACHE, \"w\") as fp:\n",
    "      json.dump(shuffledIds.tolist(), fp)\n",
    "  else:\n",
    "    with open(CACHE, \"r\") as fp:\n",
    "      idFromFile = json.load(fp)\n",
    "      assert(idFromFile == shuffledIds.tolist())\n",
    "  \n",
    "  numTrain = int(len(shuffledIds) * TRAIN_RATIO)\n",
    "  numTest = int(len(shuffledIds) * TEST_RATIO)\n",
    "  numVal = len(shuffledIds) - numTrain - numTest\n",
    "  print(f\"numTrain: {numTrain}; numTest: {numTest}; numVal: {numVal}\")\n",
    "\n",
    "  return (shuffledIds[:numTrain], shuffledIds[numTrain:numTrain + numTest], shuffledIds[numTrain + numTest:])\n",
    "\n",
    "trainIds, testIds, valIds = getShaderIdSplit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset splits for each architecture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-31 13:54:44,527 - misc.ComplexDatasetSnapshotter - INFO - White hash for (1024, 768): 908b6cfc9aef496dd5ab5c5540d80c6383ed6e92f86044574c996315381bc064\n",
      "2023-12-31 13:54:44,528 - misc.ComplexDatasetSnapshotter - INFO - Transparent black hash for (1024, 768): bbd05cf6097ac9b1f89ea29d2542c1b7b67ee46848393895f5a9e43fa1f621e5\n",
      "2023-12-31 13:54:44,537 - misc.ComplexDatasetSnapshotter - INFO - White hash for (800, 600): d883267b40e389a772f00ef4c50d49471138afed85da8f101de16ad6cf5a9d9f\n",
      "2023-12-31 13:54:44,538 - misc.ComplexDatasetSnapshotter - INFO - Transparent black hash for (800, 600): 124617c1f65e92d3bc895fbd869e4bb16a30754b198f59e6e973949b9aaa1b01\n",
      "2023-12-31 13:54:44,564 - misc.ComplexDatasetSnapshotter - INFO - White hash for (1920, 1080): 598ddbfa658eaf70a2e0c50fa12f914c28a4496bbb150a21d6d77d73b0d8c55d\n",
      "2023-12-31 13:54:44,565 - misc.ComplexDatasetSnapshotter - INFO - Transparent black hash for (1920, 1080): 788ae0147bdf979a6575938ca2d7d4403788588f7be2010f03776c968fd1ab49\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "359a12e022694bd0b6ebb2b380d3889c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28278 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95e66ebd64b649c4ac385925ec3f24ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28278 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EnvironmentFilter_EnvId1 = 447888\n",
      "EnvironmentFilter_EnvId2 = 20669\n",
      "EnvironmentFilter_EnvId3 = 20669\n",
      "EnvironmentFilter_EnvId4 = 20669\n",
      "EnvironmentFilter_EnvId5 = 20669\n",
      "EnvironmentFilter_EnvId6 = 20669\n",
      "EnvironmentFilter_EnvId7 = 20669\n",
      "EnvironmentFilter_EnvId8 = 20669\n",
      "WidthHeightFilter_1024-768 = 551233\n",
      "WidthHeightFilter_800-600 = 20669\n",
      "WidthHeightFilter_1920-1080 = 20669\n",
      "ResourceFilter_resource1 = 126226\n",
      "ResourceFilter_resourceNone = 188875\n",
      "ResourceFilter_resource2 = 13878\n",
      "ResourceFilter_resource3 = 13873\n",
      "ResourceFilter_resource4 = 13873\n",
      "ResourceFilter_resource5 = 13875\n",
      "ResourceFilter_resource6 = 13876\n",
      "ResourceFilter_resource7 = 13872\n",
      "ResourceFilter_resource8 = 13867\n",
      "ResourceFilter_resource9 = 13872\n",
      "ResourceFilter_resource10 = 13881\n",
      "ResourceFilter_resource11 = 13873\n",
      "ResourceFilter_resource12 = 13879\n",
      "ResourceFilter_resource13 = 13871\n",
      "ResourceFilter_resource14 = 13869\n",
      "ResourceFilter_resource15 = 13868\n",
      "ResourceFilter_resource16 = 13874\n",
      "ResourceFilter_resource17 = 13874\n",
      "ResourceFilter_resource18 = 13872\n",
      "ResourceFilter_resource19 = 13869\n",
      "ResourceFilter_resource20 = 13869\n",
      "ResourceFilter_resource21 = 13885\n",
      "CycleTrialsFilter_30cycles-10trials = 592571\n",
      "ErrorFilter_error0 = 375419\n",
      "ErrorFilter_error1 = 174468\n",
      "ErrorFilter_error2 = 14027\n",
      "ErrorFilter_error3 = 904\n",
      "ErrorFilter_error5 = 27752\n",
      "ErrorFilter_error100 = 1\n",
      "TraceAvailabilityFilter_noTrace = 206067\n",
      "TraceAvailabilityFilter_haveTrace = 386504\n",
      "ImageHashFilter_normalHash = 376778\n",
      "ImageHashFilter_victimHash = 12554\n",
      "AugmentationFilter_aug0 = 578732\n",
      "AugmentationFilter_aug20000 = 13839\n",
      "TimeThresholdFilter_meanBelowOrEqualThreshold10 = 389233\n",
      "TimeThresholdFilter_meanAboveThreshold10 = 99\n",
      "TimeThresholdFilter_NaN = 203239\n",
      "SpvTokenizedLengthFilter_belowOrEqualThreshold4096 = 328121\n",
      "SpvTokenizedLengthFilter_aboveThreshold4096 = 75232\n",
      "SpvTokenizedLengthFilter_failedTokenize = 343\n",
      "ShadertoyIdFilter_trainShdrExprs = 474027\n",
      "ShadertoyIdFilter_testShdrExprs = 29612\n",
      "ShadertoyIdFilter_valShdrExprs = 88932\n"
     ]
    }
   ],
   "source": [
    "from misc.ComplexDatasetSnapshotter import (\n",
    "    EnvironmentFilter,\n",
    "    CycleTrialsFilter,\n",
    "    ErrorFilter,\n",
    "    ShadertoyIdFilter,\n",
    "    WidthHeightFilter,\n",
    "    ResourceFilter,\n",
    "    TraceAvailabilityFilter,\n",
    "    SpvTokenizedLengthFilter,\n",
    "    TraceDuplicationPostFilter,\n",
    "    AugmentationFilter,\n",
    "    TimeThresholdFilter,\n",
    "    ImageHashFilter,\n",
    "    ComplexDatasetSnapshotter\n",
    ")\n",
    "from misc.Directory import (\n",
    "  getIntermediateDir\n",
    ")\n",
    "\n",
    "import logging\n",
    "import hashlib\n",
    "import pickle\n",
    "\n",
    "logging.basicConfig(\n",
    "  level=logging.INFO,\n",
    "  format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "\n",
    "snapshotter = ComplexDatasetSnapshotter()\n",
    "\n",
    "# Basic filters\n",
    "snapshotter.registerFilter(EnvironmentFilter())\n",
    "snapshotter.registerFilter(WidthHeightFilter())\n",
    "snapshotter.registerFilter(ResourceFilter())\n",
    "snapshotter.registerFilter(CycleTrialsFilter())\n",
    "snapshotter.registerFilter(ErrorFilter())\n",
    "snapshotter.registerFilter(TraceAvailabilityFilter())\n",
    "snapshotter.registerFilter(ImageHashFilter())\n",
    "snapshotter.registerFilter(AugmentationFilter())\n",
    "snapshotter.registerFilter(TimeThresholdFilter(10))\n",
    "\n",
    "lengthFilter = SpvTokenizedLengthFilter()\n",
    "lengthFilter.setThreshold(4096)\n",
    "\n",
    "if os.path.isfile(os.path.join(getIntermediateDir(), \"./lengthFilterCache.json\")):\n",
    "    lengthFilter.readFromCache(os.path.join(getIntermediateDir(), \"./lengthFilterCache.json\"))\n",
    "else:\n",
    "    lengthFilter.process(parallel=True)\n",
    "    lengthFilter.writeToCache(os.path.join(getIntermediateDir(), \"./lengthFilterCache.json\"))\n",
    "\n",
    "snapshotter.registerFilter(lengthFilter)\n",
    "\n",
    "# Train / test split filter\n",
    "shdrIdFilter = ShadertoyIdFilter()\n",
    "shdrIdFilter.registerGroup(\"trainShdrExprs\", trainIds.tolist())\n",
    "shdrIdFilter.registerGroup(\"testShdrExprs\", testIds.tolist())\n",
    "shdrIdFilter.registerGroup(\"valShdrExprs\", valIds.tolist())\n",
    "snapshotter.registerFilter(shdrIdFilter)\n",
    "\n",
    "snapshotter.examineGroups(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset FragPerfSnapshotTracedFinalDataset-RX7900GRE-Val-TimeFiltered.dat:\n",
      "=> Train Set Filter Interpretation:\n",
      "  Base expr id: 20669 items\n",
      "  Intersect with ResourceFilter_resource1: 14084 items\n",
      "  After ResourceFilter: 14084 items\n",
      "  Intersect with ErrorFilter_error0: 14084 items\n",
      "  After ErrorFilter: 14084 items\n",
      "  Intersect with TraceAvailabilityFilter_haveTrace: 14080 items\n",
      "  After TraceAvailabilityFilter: 14080 items\n",
      "  Intersect with ImageHashFilter_normalHash: 13925 items\n",
      "  After ImageHashFilter: 13925 items\n",
      "  Intersect with SpvTokenizedLengthFilter_belowOrEqualThreshold4096: 11360 items\n",
      "  After SpvTokenizedLengthFilter: 11360 items\n",
      "  Intersect with TimeThresholdFilter_meanBelowOrEqualThreshold10: 11360 items\n",
      "  After TimeThresholdFilter: 11360 items\n",
      "  Intersect with ShadertoyIdFilter_trainShdrExprs: 9049 items\n",
      "  After ShadertoyIdFilter: 9049 items\n",
      "  Returning expr id: 9049 items\n",
      "=> Test Set Filter Interpretation:\n",
      "  Base expr id: 20669 items\n",
      "  Intersect with ResourceFilter_resource1: 14084 items\n",
      "  After ResourceFilter: 14084 items\n",
      "  Intersect with ErrorFilter_error0: 14084 items\n",
      "  After ErrorFilter: 14084 items\n",
      "  Intersect with TraceAvailabilityFilter_haveTrace: 14080 items\n",
      "  After TraceAvailabilityFilter: 14080 items\n",
      "  Intersect with ImageHashFilter_normalHash: 13925 items\n",
      "  After ImageHashFilter: 13925 items\n",
      "  Intersect with SpvTokenizedLengthFilter_belowOrEqualThreshold4096: 11360 items\n",
      "  After SpvTokenizedLengthFilter: 11360 items\n",
      "  Intersect with TimeThresholdFilter_meanBelowOrEqualThreshold10: 11360 items\n",
      "  After TimeThresholdFilter: 11360 items\n",
      "  Intersect with ShadertoyIdFilter_testShdrExprs: 559 items\n",
      "  After ShadertoyIdFilter: 559 items\n",
      "  Returning expr id: 559 items\n",
      "=> Val Set Filter Interpretation:\n",
      "  Base expr id: 20669 items\n",
      "  Intersect with ResourceFilter_resource1: 14084 items\n",
      "  After ResourceFilter: 14084 items\n",
      "  Intersect with ErrorFilter_error0: 14084 items\n",
      "  After ErrorFilter: 14084 items\n",
      "  Intersect with TraceAvailabilityFilter_haveTrace: 14080 items\n",
      "  After TraceAvailabilityFilter: 14080 items\n",
      "  Intersect with ImageHashFilter_normalHash: 13925 items\n",
      "  After ImageHashFilter: 13925 items\n",
      "  Intersect with SpvTokenizedLengthFilter_belowOrEqualThreshold4096: 11360 items\n",
      "  After SpvTokenizedLengthFilter: 11360 items\n",
      "  Intersect with TimeThresholdFilter_meanBelowOrEqualThreshold10: 11360 items\n",
      "  After TimeThresholdFilter: 11360 items\n",
      "  Intersect with ShadertoyIdFilter_valShdrExprs: 1752 items\n",
      "  After ShadertoyIdFilter: 1752 items\n",
      "  Returning expr id: 1752 items\n",
      "Train samples: 9049\n",
      "Test samples: 559\n",
      "Val samples: 1752\n",
      "Hash for c:\\Projects\\NGPP\\vkPredict\\misc\\.././intermediates\\./FragPerfSnapshotTracedFinalDataset-RX7900GRE-Val-TimeFiltered.dat:\n",
      "- md5sum: 0bb96ffc80f47759cf639d7cac92eb7e\n",
      "Dataset FragPerfSnapshotTracedFinalDataset-RX6600XT-Refresh-Val-TimeFiltered.dat:\n",
      "=> Train Set Filter Interpretation:\n",
      "  Base expr id: 20669 items\n",
      "  Intersect with ResourceFilter_resource1: 14358 items\n",
      "  After ResourceFilter: 14358 items\n",
      "  Intersect with ErrorFilter_error0: 14358 items\n",
      "  After ErrorFilter: 14358 items\n",
      "  Intersect with TraceAvailabilityFilter_haveTrace: 14357 items\n",
      "  After TraceAvailabilityFilter: 14357 items\n",
      "  Intersect with ImageHashFilter_normalHash: 14318 items\n",
      "  After ImageHashFilter: 14318 items\n",
      "  Intersect with SpvTokenizedLengthFilter_belowOrEqualThreshold4096: 11655 items\n",
      "  After SpvTokenizedLengthFilter: 11655 items\n",
      "  Intersect with TimeThresholdFilter_meanBelowOrEqualThreshold10: 11655 items\n",
      "  After TimeThresholdFilter: 11655 items\n",
      "  Intersect with ShadertoyIdFilter_trainShdrExprs: 9296 items\n",
      "  After ShadertoyIdFilter: 9296 items\n",
      "  Returning expr id: 9296 items\n",
      "=> Test Set Filter Interpretation:\n",
      "  Base expr id: 20669 items\n",
      "  Intersect with ResourceFilter_resource1: 14358 items\n",
      "  After ResourceFilter: 14358 items\n",
      "  Intersect with ErrorFilter_error0: 14358 items\n",
      "  After ErrorFilter: 14358 items\n",
      "  Intersect with TraceAvailabilityFilter_haveTrace: 14357 items\n",
      "  After TraceAvailabilityFilter: 14357 items\n",
      "  Intersect with ImageHashFilter_normalHash: 14318 items\n",
      "  After ImageHashFilter: 14318 items\n",
      "  Intersect with SpvTokenizedLengthFilter_belowOrEqualThreshold4096: 11655 items\n",
      "  After SpvTokenizedLengthFilter: 11655 items\n",
      "  Intersect with TimeThresholdFilter_meanBelowOrEqualThreshold10: 11655 items\n",
      "  After TimeThresholdFilter: 11655 items\n",
      "  Intersect with ShadertoyIdFilter_testShdrExprs: 567 items\n",
      "  After ShadertoyIdFilter: 567 items\n",
      "  Returning expr id: 567 items\n",
      "=> Val Set Filter Interpretation:\n",
      "  Base expr id: 20669 items\n",
      "  Intersect with ResourceFilter_resource1: 14358 items\n",
      "  After ResourceFilter: 14358 items\n",
      "  Intersect with ErrorFilter_error0: 14358 items\n",
      "  After ErrorFilter: 14358 items\n",
      "  Intersect with TraceAvailabilityFilter_haveTrace: 14357 items\n",
      "  After TraceAvailabilityFilter: 14357 items\n",
      "  Intersect with ImageHashFilter_normalHash: 14318 items\n",
      "  After ImageHashFilter: 14318 items\n",
      "  Intersect with SpvTokenizedLengthFilter_belowOrEqualThreshold4096: 11655 items\n",
      "  After SpvTokenizedLengthFilter: 11655 items\n",
      "  Intersect with TimeThresholdFilter_meanBelowOrEqualThreshold10: 11655 items\n",
      "  After TimeThresholdFilter: 11655 items\n",
      "  Intersect with ShadertoyIdFilter_valShdrExprs: 1792 items\n",
      "  After ShadertoyIdFilter: 1792 items\n",
      "  Returning expr id: 1792 items\n",
      "Train samples: 9296\n",
      "Test samples: 567\n",
      "Val samples: 1792\n",
      "Hash for c:\\Projects\\NGPP\\vkPredict\\misc\\.././intermediates\\./FragPerfSnapshotTracedFinalDataset-RX6600XT-Refresh-Val-TimeFiltered.dat:\n",
      "- md5sum: 6c328b7f25fda82ca71d94fdc763935c\n"
     ]
    }
   ],
   "source": [
    "canonicalFilter = [\n",
    "    [('CycleTrialsFilter', '30cycles-10trials')],\n",
    "    [('WidthHeightFilter', '1024-768')],\n",
    "    [('AugmentationFilter', 'aug0')]\n",
    "]\n",
    "\n",
    "commonAdditionalFilters = [\n",
    "    [('ResourceFilter', 'resource1')],\n",
    "    [('ErrorFilter', 'error0')],\n",
    "    [('TraceAvailabilityFilter', 'haveTrace')],\n",
    "    [('ImageHashFilter', 'normalHash')],\n",
    "    [('SpvTokenizedLengthFilter', 'belowOrEqualThreshold4096')],\n",
    "    [('TimeThresholdFilter', 'meanBelowOrEqualThreshold10')]\n",
    "]\n",
    "\n",
    "candidateDatasets = {\n",
    "    \"RX7900GRE\": {\n",
    "        \"baseFilters\": canonicalFilter + [[('EnvironmentFilter', 'EnvId7')]],\n",
    "        \"additionalFilters\": commonAdditionalFilters,\n",
    "        \"trainAdditionalFilters\": [\n",
    "            [('ShadertoyIdFilter', 'trainShdrExprs')]\n",
    "        ],\n",
    "        \"testAdditionalFilters\": [\n",
    "            [('ShadertoyIdFilter', 'testShdrExprs')]\n",
    "        ],\n",
    "        \"valAdditionalFilters\": [\n",
    "            [('ShadertoyIdFilter', 'valShdrExprs')]\n",
    "        ]\n",
    "    },\n",
    "    \"RX6600XT-Refresh\": {\n",
    "        \"baseFilters\": canonicalFilter + [[('EnvironmentFilter', 'EnvId8')]],\n",
    "        \"additionalFilters\": commonAdditionalFilters,\n",
    "        \"trainAdditionalFilters\": [\n",
    "            [('ShadertoyIdFilter', 'trainShdrExprs')]\n",
    "        ],\n",
    "        \"testAdditionalFilters\": [\n",
    "            [('ShadertoyIdFilter', 'testShdrExprs')]\n",
    "        ],\n",
    "        \"valAdditionalFilters\": [\n",
    "            [('ShadertoyIdFilter', 'valShdrExprs')]\n",
    "        ]\n",
    "    },\n",
    "}\n",
    "\n",
    "for setName, setDesc in candidateDatasets.items():\n",
    "    outputName = f\"FragPerfSnapshotTracedFinalDataset-{setName}-Val-TimeFiltered.dat\"\n",
    "    outputPath = os.path.join(getIntermediateDir(), f\"./{outputName}\")\n",
    "    print(f\"Dataset {outputName}:\")\n",
    "\n",
    "    # first we go interpretation\n",
    "    baseResults = snapshotter.evalFilters(setDesc['baseFilters'])\n",
    "    \n",
    "    print(f\"=> Train Set Filter Interpretation:\")\n",
    "    trainExprIds = snapshotter.interpretFilters(\n",
    "        set(baseResults), setDesc['additionalFilters'] + setDesc['trainAdditionalFilters']\n",
    "    )\n",
    "\n",
    "    print(f\"=> Test Set Filter Interpretation:\")\n",
    "    testExprIds = snapshotter.interpretFilters(\n",
    "        set(baseResults), setDesc['additionalFilters'] + setDesc['testAdditionalFilters']\n",
    "    )\n",
    "\n",
    "    print(f\"=> Val Set Filter Interpretation:\")\n",
    "    valExprIds = snapshotter.interpretFilters(\n",
    "        set(baseResults), setDesc['additionalFilters'] + setDesc['valAdditionalFilters']\n",
    "    )\n",
    "\n",
    "    if os.path.isfile(outputPath):\n",
    "        print(f\"=> file {outputPath} is already there, verify\")\n",
    "\n",
    "        with open(outputPath, \"rb\") as f:\n",
    "            dataDict = pickle.load(f)\n",
    "            if len(dataDict['train']) != len(trainExprIds):\n",
    "                raise Exception(f\"{outputPath} got train length {len(dataDict['train'])}, but from filters we got {len(trainExprIds)}\")\n",
    "            \n",
    "            if len(dataDict['test']) != len(testExprIds):\n",
    "                raise Exception(f\"{outputPath} got test length {len(dataDict['test'])}, but from filters we got {len(testExprIds)}\")\n",
    "            \n",
    "            if len(dataDict['val']) != len(valExprIds):\n",
    "                raise Exception(f\"{outputPath} got val length {len(dataDict['val'])}, but from filters we got {len(valExprIds)}\")\n",
    "        \n",
    "        del dataDict\n",
    "\n",
    "    else:\n",
    "        trainLen, testLen, valLen = snapshotter.doSnapshot(\n",
    "            outputPath,\n",
    "            trainGroupFilters=setDesc['baseFilters'] + setDesc['additionalFilters'] + setDesc['trainAdditionalFilters'],\n",
    "            testGroupFilters=setDesc['baseFilters'] + setDesc['additionalFilters'] + setDesc['testAdditionalFilters'],\n",
    "            valGroupFilters=setDesc['baseFilters'] + setDesc['additionalFilters'] + setDesc['valAdditionalFilters']\n",
    "        )\n",
    "        assert(len(trainExprIds) == trainLen)\n",
    "        assert(len(testExprIds) == testLen)\n",
    "        assert(len(valExprIds) == valLen)\n",
    "\n",
    "        with open(outputPath, \"rb\") as f:\n",
    "            file_hash = hashlib.md5()\n",
    "            chunk = f.read(8192)\n",
    "            while chunk:\n",
    "                file_hash.update(chunk)\n",
    "                chunk = f.read(8192)\n",
    "\n",
    "        print(f\"Hash for {outputPath}:\\n- md5sum: {file_hash.hexdigest()}\")\n",
    "        with open(outputPath + \".md5sum\", \"w\") as f:\n",
    "            f.write(file_hash.hexdigest())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
