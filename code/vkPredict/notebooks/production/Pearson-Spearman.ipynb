{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.path.join(os.path.abspath(''), '../../'))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.colors import LogNorm\n",
    "from palettable.scientific.sequential import Oslo_5_r\n",
    "\n",
    "from misc.normalization import (\n",
    "    LogNormalizer,\n",
    "    DummyNormalizer\n",
    ")\n",
    "from misc.Directory import getVkPredictRootDir\n",
    "from scipy.stats import spearmanr\n",
    "from misc.metric import compute_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = {\n",
    "    \"SH\": \"_base\",\n",
    "    \"PILR\": \"_pilr\",\n",
    "    \"NN\": \"\",\n",
    "    \"SH-Const\": \"_const_base\",\n",
    "    \"PILR-Const\": \"_const_pilr\",\n",
    "    \"NN-Const\": \"_const_fixed\",\n",
    "}\n",
    "\n",
    "names = {\n",
    "    '3060': 'RTX3060',\n",
    "    '630': 'UHD630',\n",
    "    '4060': 'RTX4060',\n",
    "    '1660': 'GTX1660Ti',\n",
    "    '7900': 'RX7900GRE'\n",
    "}\n",
    "\n",
    "measured = {k: {} for k in methods.keys()}\n",
    "predicted = {k: {} for k in methods.keys()}\n",
    "\n",
    "for name in names.keys():\n",
    "    for method in methods:\n",
    "        if method == \"NN\" or method == \"NN-Const\":\n",
    "            measured[method][name] = LogNormalizer().invNormalize(np.load(os.path.join(getVkPredictRootDir(), f'validation/{name}{methods[method]}_labels.npy')))\n",
    "            predicted[method][name] = LogNormalizer().invNormalize(np.load(os.path.join(getVkPredictRootDir(), f'validation/{name}{methods[method]}_preds.npy')))\n",
    "        else:\n",
    "            measured[method][name] = np.load(os.path.join(getVkPredictRootDir(), f'validation/{name}{methods[method]}_labels.npy'))\n",
    "            predicted[method][name] = np.load(os.path.join(getVkPredictRootDir(), f'validation/{name}{methods[method]}_preds.npy'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Platform\tSH-mape\tSH-sprm\tPILR-mape\tPILR-sprm\tNN-mape\tNN-sprm\tSH-Const-mape\tSH-Const-sprm\tPILR-Const-mape\tPILR-Const-sprm\tNN-Const-mape\tNN-Const-sprm\t\n",
      "RTX3060 \t0.7526\t0.9584\t0.469\t0.92\t0.4044\t0.9642\t0.7602\t0.7131\t0.8643\t0.8551\t0.8102\t0.8608\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Projects\\NGPP\\vkPredict\\notebooks\\production\\../..\\misc\\metric.py:39: RuntimeWarning: Mean of empty slice.\n",
      "  ((candRealTime - candPredTime)**2).mean(axis=0)\n",
      "c:\\Projects\\NGPP\\venv\\lib\\site-packages\\numpy\\core\\_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "c:\\Projects\\NGPP\\venv\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UHD630  \t0.3073\t0.9594\t0.2732\t0.9676\t0.266\t0.9722\t0.6697\t0.7152\t0.7287\t0.8503\t0.7042\t0.8749\t\n",
      "RTX4060 \t0.8117\t0.9588\t0.556\t0.929\t0.4462\t0.9632\t0.7954\t0.7118\t0.9039\t0.8563\t0.981\t0.7518\t\n",
      "GTX1660Ti\t0.8256\t0.9607\t0.5499\t0.9353\t0.4159\t0.9681\t0.802\t0.7142\t0.9026\t0.8571\t1.096\t0.8784\t\n",
      "RX7900GRE\t0.3632\t0.951\t0.3628\t0.9433\t0.2654\t0.9578\t0.6865\t0.6857\t0.8119\t0.8388\t0.5116\t0.8448\t\n"
     ]
    }
   ],
   "source": [
    "ss = \"Platform\\t\"\n",
    "for method in methods:\n",
    "    ss += f\"{method}-mape\\t{method}-sprm\\t\"\n",
    "print(ss)\n",
    "\n",
    "for i, archName in enumerate(names.keys()):\n",
    "    ss = f\"{names[archName]:8}\\t\"\n",
    "    for method in methods:\n",
    "        mape = compute_metrics(predicted[method][archName], measured[method][archName])['mape']\n",
    "        corr, _ = spearmanr(measured[method][archName], predicted[method][archName])\n",
    "        ss += f\"{mape:.4}\\t{corr:.4}\\t\"\n",
    "    \n",
    "    print(ss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'3060'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m pre \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSH\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 10\u001b[0m     pre \u001b[38;5;241m=\u001b[39m \u001b[43mpredicted\u001b[49m\u001b[43m[\u001b[49m\u001b[43marchName\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPILR\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     12\u001b[0m     pre \u001b[38;5;241m=\u001b[39m predicted_pilr[archName]\n",
      "\u001b[1;31mKeyError\u001b[0m: '3060'"
     ]
    }
   ],
   "source": [
    "# for method in ['SH', 'PILR', 'NN']:\n",
    "#     for i, archName in enumerate(names.keys()):\n",
    "#         # corrNN, _ = pearsonr(measured[archName], predicted[archName])\n",
    "#         # corrPILR, _ = pearsonr(measured_base[archName], predicted_base[archName])\n",
    "#         # corrSH, _ = pearsonr(measured_pilr[archName], predicted_pilr[archName])\n",
    "#         # print(f\"{archName} Pearson: corrNN={corrNN:.4f}, corrPILR={corrPILR:.4f} ({'NN' if corrNN > corrPILR else 'PILR'} better)\")\n",
    "\n",
    "#         pre = None\n",
    "#         if method == \"SH\":\n",
    "#             pre = predicted[archName]\n",
    "#         elif method == \"PILR\":\n",
    "#             pre = predicted_pilr[archName]\n",
    "            \n",
    "#         mapeNN = compute_metrics(predicted[archName], measured[archName])['mape']\n",
    "#         corrNN, _ = spearmanr(measured[archName], predicted[archName])\n",
    "#         mapeNNAvg += mapeNN\n",
    "\n",
    "#         mapeSH = compute_metrics(predicted_base[archName], measured_base[archName])['mape']\n",
    "#         corrSH, _ = spearmanr(measured_base[archName], predicted_base[archName])\n",
    "#         mapeSHAvg += mapeSH\n",
    "\n",
    "#         mapePILR = compute_metrics(predicted_pilr[archName], measured_pilr[archName])['mape']\n",
    "#         corrPILR, _ = spearmanr(measured_pilr[archName], predicted_pilr[archName])\n",
    "#         mapePILRAvg += mapePILR\n",
    "\n",
    "#         spearmanBig = max(corrNN, corrPILR, corrSH)\n",
    "#         mapeSmall = min(mapeNN, mapePILR, mapeSH)\n",
    "\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
