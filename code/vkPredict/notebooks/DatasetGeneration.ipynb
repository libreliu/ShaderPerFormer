{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Snapshot Dataset Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common Premable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.path.join(os.path.abspath(''), '../'))\n",
    "\n",
    "import peewee as pw\n",
    "from toyDb.databases import ExperimentDb, ShaderDb\n",
    "from toyDb.utils.Directory import getToyDbRootDir\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "import hashlib\n",
    "\n",
    "ExperimentDb.init_from_default_db()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Snapshot format\n",
    "\n",
    "Snapshot format is as follows:\n",
    "\n",
    "~~FragPerfSnapshotDataset~~\n",
    "  - This is deprecated\n",
    "\n",
    "FragTokenizedDataset (Consumed by `FragmentMaskedLMDataset`):\n",
    "- input_ids: tokenizer output of SPIR-V shader representation\n",
    "- NOTE: This are not trunctuated, since DataCollator will handle trunctuation\n",
    "\n",
    "FragPerfSnapshotTracedDataset:\n",
    "- \"environmentId\": self.environmentId\n",
    "- \"shaderId\": expr.shader.shader_id\n",
    "- \"fragSpv\": expr.shader.fragment_spv\n",
    "  - `SPIR-V bytes`\n",
    "- \"traceFragSpv\": expr.trace.traced_fragment_spv\n",
    "  - `SPIR-V bytes`\n",
    "- \"timeMean\": result_mean\n",
    "  - `float`\n",
    "- \"bbIdxMap\": {int(k): v for k, v in json.loads(expr.trace.bb_idx_map).items()}\n",
    "  - `dict[int, int]`\n",
    "- \"bbTraceCounters\": json.loads(expr.trace.bb_trace_counters)\n",
    "  - `List[int]`\n",
    "\n",
    "\n",
    "### Multi-environment considerations\n",
    "\n",
    "Current flow is to add the environment suffix onto the json / dat filename.\n",
    "\n",
    "### Persistence considerations\n",
    "```python\n",
    "with open(\"your_filename.png\", \"rb\") as f:\n",
    "    file_hash = hashlib.md5()\n",
    "    chunk = f.read(8192)\n",
    "    while chunk:\n",
    "        file_hash.update(chunk)\n",
    "        chunk = f.read(8192)\n",
    "\n",
    "print(file_hash.hexdigest())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shader blacklist\n",
    "\n",
    "This is stored in `shaderBlacklist.json`.\n",
    "\n",
    "Reason is given below\n",
    "- `fl2yzG`: Compiled SPIR-V have too many IDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3060 Dataset Generation\n",
    "\n",
    "Environment details:\n",
    "- libreliu-GCL-Arch\n",
    "- Linux 6.1.58-1-lts\n",
    "- Intel(R) Core(TM) i7-10700K CPU @ 3.80GHz\n",
    "- NVIDIA GeForce RTX 3060\n",
    "- NVIDIA 535.113.01\n",
    "- gfxclk1605-memclk7500\n",
    "\n",
    "The results are saved to\n",
    "- FragPerfSnapshotTracedDataset4096-3060.dat\n",
    "\n",
    "> NOTE: `FragPerfSnapshotDataset4096-3060.json` is deprecated.\n",
    "> Non-trace version should also consume the traced dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.FragmentPerformanceWithTraceDataset import FragmentPerformanceWithTraceDataset\n",
    "from dataset.FragmentPerformanceTracedSnapshotDataset import (\n",
    "    FragmentPerformanceTracedSnapshotDataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment selected: \n",
      "- libreliu-GCL-Arch\n",
      "-  Intel(R) Core(TM) i7-10700K CPU @ 3.80GHz\n",
      "- NVIDIA GeForce RTX 3060\n",
      "- NVIDIA 535.113.01\n",
      "- gfxclk1605-memclk7500\n"
     ]
    }
   ],
   "source": [
    "selectedEnv = ExperimentDb.Environment.select()[0]\n",
    "print(f\"Environment selected: \\n\"\n",
    "      f\"- {selectedEnv.node}\\n\"\n",
    "      f\"- {selectedEnv.cpu}\\n\"\n",
    "      f\"- {selectedEnv.gpu}\\n\"\n",
    "      f\"- {selectedEnv.gpu_driver}\\n\"\n",
    "      f\"- {selectedEnv.comment}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the traceDataset: 13867\n"
     ]
    }
   ],
   "source": [
    "traceDataset = FragmentPerformanceWithTraceDataset(\n",
    "  environmentId=selectedEnv.id,\n",
    "  filteredNumCycles=ExperimentDb.CANONICAL_NUM_CYCLES,\n",
    "  filteredNumTrials=ExperimentDb.CANONICAL_NUM_TRIALS,\n",
    "  useBlackList=True\n",
    ")\n",
    "\n",
    "print(f\"Length of the traceDataset: {len(traceDataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generation of FragPerfSnapshotTracedDataset4096-3060.dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-01 23:22:35,040 - misc.snapshotFragPerfTraceDataset - INFO - maxTokenizedLength == 4096\n",
      "100%|██████████| 13867/13867 [01:36<00:00, 144.00it/s]\n",
      "2023-11-01 23:24:11,354 - misc.snapshotFragPerfTraceDataset - INFO - Total: 13867, filtered: 11274, (81.301% of the original) train: 9019, test: 2255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed samples (total 0): []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training sample serialization: 100%|██████████| 9019/9019 [00:00<00:00, 48821.96it/s]\n",
      "Testing sample serialization: 100%|██████████| 2255/2255 [00:00<00:00, 47581.50it/s]\n",
      "2023-11-01 23:24:11,700 - misc.snapshotFragPerfTraceDataset - INFO - Snapshot written to /home/libreliu/Projects/NGPP/vkPredict/misc/.././intermediates/./FragPerfSnapshotTracedDataset4096-3060.dat\n"
     ]
    }
   ],
   "source": [
    "import misc.snapshotFragPerfTraceDataset\n",
    "from misc.Directory import (\n",
    "  getIntermediateDir,\n",
    "  getVkPredictRootDir\n",
    ")\n",
    "import misc.TokenizerBuilder\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(\n",
    "  level=logging.INFO,\n",
    "  format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "\n",
    "destFile = os.path.join(\n",
    "  getIntermediateDir(),\n",
    "  \"./FragPerfSnapshotTracedDataset4096-3060.dat\"\n",
    ")\n",
    "\n",
    "OVERRIDE_DATASET_SNAPSHOT_FILE = False\n",
    "DO_SNAPSHOT = True\n",
    "if os.path.isfile(destFile):\n",
    "  print(f\"You're overriding {destFile} if you run this cell.\")\n",
    "  print(f\"Toggle the above to True if needed\")\n",
    "\n",
    "  if OVERRIDE_DATASET_SNAPSHOT_FILE:\n",
    "    DO_SNAPSHOT = True\n",
    "  else:\n",
    "    DO_SNAPSHOT = False\n",
    "\n",
    "if DO_SNAPSHOT:\n",
    "  misc.snapshotFragPerfTraceDataset.snapshot(\n",
    "    # train ratio\n",
    "    0.8,\n",
    "    # output dir\n",
    "    destFile,\n",
    "    # max tokenized length\n",
    "    4096,\n",
    "    # tokenizer\n",
    "    misc.TokenizerBuilder.build_tokenizer(\"HfTracedSpvTokenizer-multiple-entrypoint\"),\n",
    "    # dset args\n",
    "    {\n",
    "      \"environmentId\": selectedEnv.id,\n",
    "      \"filteredNumCycles\": ExperimentDb.CANONICAL_NUM_CYCLES,\n",
    "      \"filteredNumTrials\": ExperimentDb.CANONICAL_NUM_TRIALS\n",
    "    }\n",
    "  )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we record a md5sum associated with the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hash for /home/libreliu/Projects/NGPP/vkPredict/misc/.././intermediates/./FragPerfSnapshotTracedDataset4096-3060.dat:\n",
      "- md5sum: 4c48549fb2b0a11237fde4592e3b5335\n"
     ]
    }
   ],
   "source": [
    "with open(destFile, \"rb\") as f:\n",
    "    file_hash = hashlib.md5()\n",
    "    chunk = f.read(8192)\n",
    "    while chunk:\n",
    "        file_hash.update(chunk)\n",
    "        chunk = f.read(8192)\n",
    "\n",
    "print(f\"Hash for {destFile}:\\n- md5sum: {file_hash.hexdigest()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we read it back to check quantity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset: 9019\n",
      "Test dataset: 2255\n",
      "Total: 11274 - 81.30093026609937%% of the original\n"
     ]
    }
   ],
   "source": [
    "from dataset.FragmentPerformanceTracedSnapshotDataset import FragmentPerformanceTracedSnapshotDataset\n",
    "\n",
    "trainDataset = FragmentPerformanceTracedSnapshotDataset(destFile, 'train')\n",
    "testDataset = FragmentPerformanceTracedSnapshotDataset(destFile, 'test')\n",
    "totalLen = len(trainDataset) + len(testDataset)\n",
    "\n",
    "print(f\"Train dataset: {len(trainDataset)}\")\n",
    "print(f\"Test dataset: {len(testDataset)}\")\n",
    "print(f\"Total: {totalLen} - {totalLen / len(traceDataset) * 100}% of the original\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
